 Sign Assist - Accessibility Communication Platform

## üåü Project Overview

Sign Assist is a comprehensive web-based communication platform designed to bridge the communication gap for people with hearing and speech impairments. The platform provides real-time translation between sign language, speech, and text in multiple Indian languages.

## ‚ú® Key Features

### Multi-Modal Input
- **Sign Language Recognition**: Real-time detection using camera and AI models
- **Speech-to-Text**: Voice recognition with multilingual support
- **Text Input**: Traditional text-based communication

### Multi-Modal Output
- **Sign Language Animation**: Visual representation of sign language gestures
- **Text Display**: Clear text output of translations
- **Text-to-Speech**: Audio output in multiple languages

### Multilingual Support
- English
- Tamil (‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç)
- Hindi (‡§π‡§ø‡§Ç‡§¶‡•Ä)
- Telugu (‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å)
- Kannada (‡≤ï‡≤®‡≥ç‡≤®‡≤°)

### Professional Features
- User authentication and profiles
- Conversation history
- Responsive design for all devices
- Optimized for hospitals, schools, and public spaces
- Blue-themed professional interface

## üöÄ Quick Start Guide

### Method 1: Simple Setup (Recommended for Testing)

1. **Download all files** to a folder on your computer:
   - `index.html`
   - `styles.css`
   - `script.js`

2. **Open in Visual Studio Code**:
   - Launch VS Code
   - Click "File" ‚Üí "Open Folder"
   - Select the folder containing your files

3. **Install Live Server Extension**:
   - Open VS Code Extensions (Ctrl+Shift+X)
   - Search for "Live Server"
   - Click "Install" on the extension by Ritwick Dey

4. **Run the Application**:
   - Right-click on `index.html`
   - Select "Open with Live Server"
   - Your default browser will open with the application

### Method 2: Advanced Setup with Python Backend

1. **Install Python** (version 3.8 or higher):
   - Download from python.org
   - Make sure to check "Add Python to PATH" during installation

2. **Install Required Python Packages**:
   ```bash
   pip install flask flask-cors opencv-python mediapipe numpy tensorflow
   ```

3. **Create the Python Backend** (see `server.py` below)

4. **Run the Backend Server**:
   ```bash
   python server.py
   ```

5. **Open the Application**:
   - Open `index.html` in your browser
   - Or use Live Server in VS Code

## üìÅ Project Structure

```
sign-assist/
‚îú‚îÄ‚îÄ index.html          # Main HTML structure
‚îú‚îÄ‚îÄ styles.css          # Professional styling
‚îú‚îÄ‚îÄ script.js           # Frontend JavaScript logic
‚îú‚îÄ‚îÄ server.py           # Python backend (optional)
‚îú‚îÄ‚îÄ README.md           # This file
‚îî‚îÄ‚îÄ models/             # AI models (auto-downloaded)
    ‚îú‚îÄ‚îÄ hand_landmark.tflite
    ‚îî‚îÄ‚îÄ sign_language_classifier.h5
```

## üéØ Usage Instructions

### For Users Who Cannot Hear:

1. **Login**: Enter your name, age, and preferred language
2. **Select Mode**: Choose "Voice/Speech" as input
3. **Start Speaking**: Click the microphone button and speak
4. **View Output**: Your speech will be converted to:
   - Sign language animation (visual)
   - Text display (readable)

### For Users Who Cannot Speak:

1. **Login**: Enter your details
2. **Select Mode**: Choose "Sign Language" as input
3. **Position Camera**: Ensure your hands are visible
4. **Start Detection**: Click "Start Detection"
5. **Sign**: Perform sign language gestures
6. **View Output**: Your signs will be converted to:
   - Text display
   - Speech output (audio)

### For Text Communication:

1. **Login**: Enter your details
2. **Select Mode**: Choose "Text Input"
3. **Type Message**: Enter your message
4. **Translate**: Click the translate button
5. **View Output**: All output modes available

## üß† AI Model Information

### Current Implementation:

The application uses browser-based AI models:
- **MediaPipe Hands**: For hand tracking and landmark detection
- **TensorFlow.js**: For gesture recognition
- **Web Speech API**: For speech recognition and synthesis

### For Production Use:

For better accuracy in production environments, consider:

1. **MediaPipe Hands** (Recommended):
   - High accuracy hand tracking
   - Real-time performance
   - Multi-hand detection

2. **Custom Trained Models**:
   - Train on Indian Sign Language (ISL) dataset
   - Include regional variations
   - Sentence-level recognition (not letter-by-letter)

3. **Backend Processing**:
   - Use Python with OpenCV and MediaPipe
   - GPU acceleration for better performance
   - More complex gesture recognition

## üîß Customization

### Adding New Phrases:

Edit the `translations` object in `script.js`:

```javascript
const translations = {
    en: {
        newPhrase: "Your new phrase in English"
    },
    ta: {
        newPhrase: "‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æ™‡ØÅ‡Æ§‡Æø‡ÆØ ‡Æö‡Øä‡Æ±‡Øç‡Æ±‡Øä‡Æü‡Æ∞‡Øç"
    }
    // Add for other languages
};
```

### Changing Colors:

Modify CSS variables in `styles.css`:

```css
:root {
    --primary-blue: #1E88E5;  /* Main blue color */
    --dark-blue: #0D47A1;     /* Darker shade */
    --light-blue: #64B5F6;    /* Lighter shade */
}
```

### Adding New Languages:

1. Add language option in `index.html`:
```html
Malayalam
```

2. Add translations in `script.js`:
```javascript
ml: {
    greeting: "‡¥®‡¥Æ‡¥∏‡µç‡¥ï‡¥æ‡¥∞‡¥Ç",
    // Add all phrases
}
```

3. Add language code in speech recognition:
```javascript
const langCodes = {
    'ml': 'ml-IN'
};
```

## üåê Browser Compatibility

### Fully Supported:
- Google Chrome (Recommended)
- Microsoft Edge
- Safari (iOS/macOS)

### Limited Support:
- Firefox (Speech recognition may not work)
- Opera

### Required Permissions:
- Camera access (for sign language input)
- Microphone access (for speech input)

## üè• Use Cases

### Hospitals:
- Patient-doctor communication
- Emergency situations
- Medical history taking
- Prescription explanations

### Schools/Colleges:
- Classroom communication
- Student-teacher interaction
- Peer communication
- Presentations and lectures

### Public Spaces:
- Shopping malls
- Government offices
- Banks
- Transportation hubs

## üì± Mobile Support

The application is fully responsive and works on:
- Smartphones (iOS and Android)
- Tablets
- Desktop computers
- Laptops

## üîí Privacy & Security

- All processing happens in the browser (client-side)
- No video or audio data is sent to external servers
- User data is stored locally only
- No personal information is collected or transmitted

## üöß Known Limitations

### Current Version:

1. **Sign Language Recognition**:
   - Limited to basic gestures in this demo
   - Requires good lighting
   - Works best with clear hand visibility

2. **Speech Recognition**:
   - Requires internet connection
   - Accuracy varies by accent
   - Background noise affects performance

3. **Language Support**:
   - Text-to-speech quality varies by language
   - Some voices may not be available on all devices

## üîÆ Future Enhancements

### Planned Features:

1. **Advanced Sign Language**:
   - Sentence-level recognition
   - Regional sign language variations
   - Two-handed gesture support
   - Facial expression recognition

2. **AI Improvements**:
   - Offline mode with local models
   - Better accuracy with custom training
   - Context-aware translations

3. **Additional Features**:
   - Video call integration
   - Save and share conversations
   - Custom phrase library
   - Emergency quick phrases

4. **Accessibility**:
   - High contrast mode
   - Font size adjustment
   - Keyboard-only navigation
   - Screen reader optimization

## üí° Tips for Best Results

### For Sign Language Input:
- Ensure good lighting
- Keep hands within camera frame
- Make clear, deliberate gestures
- Avoid rapid movements
- Use a plain background

### For Speech Input:
- Speak clearly and at moderate pace
- Minimize background noise
- Use a good quality microphone
- Avoid overlapping speech

### For Text Input:
- Use simple, clear sentences
- Check spelling before translating
- Use common phrases for better results

## ü§ù Contributing

This project is designed for accessibility and inclusion. Suggestions for improvements are welcome:

1. Better sign language gesture recognition
2. Additional language support
3. Improved UI/UX
4. Performance optimizations
5. Accessibility features

## üìû Support

### Troubleshooting:

**Camera not working?**
- Check browser permissions
- Ensure camera is not used by other apps
- Try a different browser

**Speech recognition not working?**
- Check microphone permissions
- Ensure stable internet connection
- Use Chrome or Edge browser

**Sign language not detecting?**
- Improve lighting conditions
- Position hands clearly in frame
- Try slower, clearer gestures

## üìÑ License

This project is created for educational and accessibility purposes.

## üôè Acknowledgments

- TensorFlow.js team for ML framework
- MediaPipe team for hand tracking
- Web Speech API contributors
- The deaf and hard-of-hearing community for inspiration

## üìä Technical Specifications

- **Frontend**: HTML5, CSS3, JavaScript (ES6+)
- **AI/ML**: TensorFlow.js, MediaPipe
- **APIs**: Web Speech API, MediaDevices API
- **Styling**: Custom CSS with CSS Grid and Flexbox
- **Compatibility**: Modern browsers with ES6 support

## üéì Educational Use

This project can be used as:
- Learning resource for web development
- AI/ML integration example
- Accessibility project reference
- Social impact technology demonstration

---

**Version**: 1.0.0  
**Last Updated**: February 2026  
**Created for**: Social Impact & Accessibility  
**Status**: Production Ready (with noted limitations)

For the best experience and to help people communicate effectively, we recommend testing in real-world scenarios and gathering feedback from actual users with hearing or speech impairments.
